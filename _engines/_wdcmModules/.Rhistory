q()
# - toRuntime Log:
print("Log: RUN wdcmModule_ETL.py")
# - clean ETL dirs
if (length(list.files(etlDir)) > 1) {
file.remove(paste0(etlDir, list.files(etlDir)))
}
if (length(list.files(etlDirGeo)) > 1) {
file.remove(paste0(etlDirGeo, list.files(etlDirGeo)))
}
# - Kerberos init
system(command = 'sudo -u analytics-privatedata kerberos-run-command analytics-privatedata hdfs dfs -ls',
wait = T)
# - Run PySpark ETL
system(command = paste0('sudo -u analytics-privatedata spark2-submit ',
sparkMaster, ' ',
sparkDeployMode, ' ',
sparkNumExecutors, ' ',
sparkDriverMemory, ' ',
sparkExecutorMemory, ' ',
sparkExecutorCores, ' ',
paste0(fPathPython, 'wdcmModule_ETL.py')
),
wait = T)
q()
params <- xmlParse(paste0(fPath, "wdcmConfig.xml"))
params <- xmlToList(params)
fPath <- paste0(getwd(), "/")
?Lc
?WMDEData::hdfs_copy_to
?setDefaultClusterOptions
?snowfall::setDefaultClusterOptions
>Rtsne::Rtsne
?Rtsne::Rtsne
